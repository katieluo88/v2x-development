{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c4d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segments import SegmentsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af50aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"b40bd5dba051369bbc18735fb23925c456eaad7b\"\n",
    "\n",
    "client = SegmentsClient(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stamp(stamp):\n",
    "    stamp_split = stamp.split(\".\")\n",
    "    if len(stamp_split[-1]) < 9:\n",
    "        stamp_split[-1] = \"0\" * (9 - len(stamp_split[-1])) + stamp_split[-1]\n",
    "    return \".\".join(stamp_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eaaed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get timestamps\n",
    "\n",
    "scene_id = 2\n",
    "\n",
    "pcd_path = f\"/media/kluo/My Passport/v2x_dataset/PointCloud/mini_{scene_id}\"\n",
    "odo_path = f\"/media/kluo/My Passport/v2x_dataset/Odometry/mini_{scene_id}\"\n",
    "\n",
    "# store all filepaths according to their header\n",
    "all_filepaths = {}\n",
    "for f in os.listdir(pcd_path):\n",
    "    if f.split(\".\")[-1] != \"pcd\":\n",
    "        continue\n",
    "    sensor, ts, stamp = f.split(\"_\")\n",
    "    stamp = check_stamp(stamp[:-4])\n",
    "    stamp = float(stamp)\n",
    "    if sensor not in all_filepaths:\n",
    "        all_filepaths[sensor] = {ts: (f, stamp)}\n",
    "    else:\n",
    "        all_filepaths[sensor][ts] = (f, stamp)\n",
    "all_sensors_list = list(all_filepaths.keys())\n",
    "\n",
    "all_filepaths[\"top\"], len(all_filepaths[\"top\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab3ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "offs_idx = 1\n",
    "for scene_id in range(1, 38):\n",
    "    pcd_dir = f'/media/kluo/My Passport/v2x_dataset/MergedPointCloud/mini_{scene_id}/'\n",
    "\n",
    "    all_files = []\n",
    "    for f in os.listdir(pcd_dir):\n",
    "        all_files.append(int(f.split(\"_\")[-1][:-4]))\n",
    "    \n",
    "    print(\"***********scene:\", scene_id)\n",
    "\n",
    "    start_idx, stop_idx = min(all_files) + offs_idx, max(all_files) + offs_idx\n",
    "    for idx in range(start_idx, stop_idx, 10):\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e144b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"ca9a282c9e77460f8360f564131a8af5_nuscenes.bin\"\n",
    "\n",
    "# with open(f\"path/to/{filename}\", \"rb\") as f:\n",
    "#     asset = client.upload_asset(f, filename=filename)\n",
    "\n",
    "# point_cloud_url = asset.url\n",
    "\n",
    "pcd_dir = f'/media/kluo/My Passport/v2x_dataset/MergedPointCloud/mini_5/'\n",
    "\n",
    "all_files = []\n",
    "for f in os.listdir(pcd_dir):\n",
    "    all_files.append(int(f.split(\"_\")[-1][:-4]))\n",
    "        \n",
    "all_point_cloud_urls = []\n",
    "# for idx in range(len(all_filepaths[\"top\"])):\n",
    "# for idx in range(0, len(all_filepaths[\"top\"]), 10):\n",
    "start_idx, stop_idx = min(all_files) + offs_idx, max(all_files) + 1\n",
    "print(start_idx, stop_idx)\n",
    "for idx in range(start_idx, stop_idx, 10):\n",
    "    filename = f\"merged_{idx}.pcd\"\n",
    "    with open(osp.join(pcd_dir, filename), \"rb\") as f:\n",
    "        asset = client.upload_asset(f, filename=filename)\n",
    "    point_cloud_url = asset.url\n",
    "    all_point_cloud_urls.append(point_cloud_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_point_cloud_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the frames\n",
    "\n",
    "# -0.0389144089103\t-0.023183467107\t0.9989570081\t0.00574816730405\n",
    "# x, y,z,w\n",
    "frames = []\n",
    "str_idx = 0\n",
    "for idx in range(start_idx, stop_idx, 10):\n",
    "    print(idx)\n",
    "    timestamp = int(all_filepaths[\"top\"][str(idx)][1]*1e9)\n",
    "    frame = {\n",
    "        \"pcd\": {\"url\": all_point_cloud_urls[str_idx], \"type\": \"pcd\"},\n",
    "        \"timestamp\": timestamp,\n",
    "    }\n",
    "    frames.append(frame)\n",
    "    str_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46eeb94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ea4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747a0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"katieluo6/TestingV2X\"\n",
    "\n",
    "name = \"sample_point_cloud_sequence_v3\"\n",
    "\n",
    "attributes = {\"frames\": frames}\n",
    "\n",
    "sample = client.add_sample(dataset, name, attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144edc48",
   "metadata": {},
   "source": [
    "# upload all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"julieberrioperez/V2X_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "offs_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca1a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_point_cloud_urls = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018694d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for scene_id in range(1, 38):\n",
    "    if scene_id == 18:\n",
    "        print(\"skipping\", scene_id)\n",
    "        continue\n",
    "    print(\"*************** scene id:\", scene_id)\n",
    "    pcd_path = f\"/media/kluo/My Passport/v2x_dataset/PointCloud/mini_{scene_id}\"\n",
    "    odo_path = f\"/media/kluo/My Passport/v2x_dataset/Odometry/mini_{scene_id}\"\n",
    "\n",
    "    # store all filepaths according to their header\n",
    "    all_filepaths = {}\n",
    "    for f in os.listdir(pcd_path):\n",
    "        if f.split(\".\")[-1] != \"pcd\":\n",
    "            continue\n",
    "        sensor, ts, stamp = f.split(\"_\")\n",
    "        stamp = check_stamp(stamp[:-4])\n",
    "        stamp = float(stamp)\n",
    "        if sensor not in all_filepaths:\n",
    "            all_filepaths[sensor] = {ts: (f, stamp)}\n",
    "        else:\n",
    "            all_filepaths[sensor][ts] = (f, stamp)\n",
    "\n",
    "    pcd_dir = f'/media/kluo/My Passport/v2x_dataset/MergedPointCloud/mini_{scene_id}/'\n",
    "    \n",
    "    all_files = []\n",
    "    for f in os.listdir(pcd_dir):\n",
    "        all_files.append(int(f.split(\"_\")[-1][:-4]))\n",
    "    \n",
    "    # start_idx, stop_idx = min(all_files), max(all_files)\n",
    "    start_idx, stop_idx = min(all_files) + offs_idx, max(all_files) + 1\n",
    "    \n",
    "    all_point_cloud_urls = []\n",
    "    for idx in range(start_idx, stop_idx, 10):\n",
    "        filename = f\"merged_{idx}.pcd\"\n",
    "        print(filename)\n",
    "        with open(osp.join(pcd_dir, filename), \"rb\") as f:\n",
    "            asset = client.upload_asset(f, filename=filename)\n",
    "        point_cloud_url = asset.url\n",
    "        print(idx, point_cloud_url)\n",
    "        all_point_cloud_urls.append(point_cloud_url)\n",
    "    scene_point_cloud_urls[scene_id] = all_point_cloud_urls\n",
    "\n",
    "    # construct the frames\n",
    "    # x, y,z,w\n",
    "    frames = []\n",
    "    str_idx = 0\n",
    "    for idx in range(start_idx, stop_idx, 10):\n",
    "        print(idx)\n",
    "        timestamp = int(all_filepaths[\"top\"][str(idx)][1]*1e9)\n",
    "        frame = {\n",
    "            \"pcd\": {\"url\": all_point_cloud_urls[str_idx], \"type\": \"pcd\"},\n",
    "            \"timestamp\": timestamp,\n",
    "        }\n",
    "        frames.append(frame)\n",
    "        str_idx += 1\n",
    "    print(\"frames:\", len(frames))\n",
    "    name = f\"point_cloud_sequence_{scene_id}\"\n",
    "\n",
    "    attributes = {\"frames\": frames}\n",
    "\n",
    "    sample = client.add_sample(dataset, name, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3998bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scene_point_cloud_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdbf0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_idxs = {}\n",
    "for scene_id in range(1, 38):\n",
    "    if scene_id == 18:\n",
    "        print(\"skipping\", scene_id)\n",
    "        continue\n",
    "    print(\"*************** scene id:\", scene_id)\n",
    "\n",
    "    pcd_dir = f'/media/kluo/My Passport/v2x_dataset/MergedPointCloud/mini_{scene_id}/'\n",
    "    \n",
    "    all_files = []\n",
    "    for f in os.listdir(pcd_dir):\n",
    "        all_files.append(int(f.split(\"_\")[-1][:-4]))\n",
    "    \n",
    "    # start_idx, stop_idx = min(all_files), max(all_files)\n",
    "    start_idx, stop_idx = min(all_files) + offs_idx, max(all_files) + 1\n",
    "    \n",
    "    for idx in range(start_idx, stop_idx, 10):\n",
    "        if scene_id not in labeled_idxs:\n",
    "            labeled_idxs[scene_id] = []\n",
    "        labeled_idxs[scene_id].append(idx)\n",
    "\n",
    "\n",
    "print(labeled_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b885306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909570d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save_dir = f\"./merged_info/\"\n",
    "save_dir = f\"/media/kluo/My Passport/v2x_dataset/merged_info_updated/\"\n",
    "\n",
    "scene_id = 5\n",
    "timestep = 200\n",
    "\n",
    "scene_info = []\n",
    "with open(osp.join(save_dir, f\"info_{scene_id}.jsonl\"), \"r\") as file:\n",
    "    for line in file:\n",
    "        scene_info.append(json.loads(line))\n",
    "len(scene_info), scene_info[timestep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8142e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "offs = 1.712120e9\n",
    "for scene_id in range(1, 37):\n",
    "\n",
    "    scene_info = []\n",
    "    with open(osp.join(save_dir, f\"info_{scene_id}.jsonl\"), \"r\") as file:\n",
    "        for line in file:\n",
    "            scene_info.append(json.loads(line))\n",
    "            \n",
    "    next_scene_info = []\n",
    "    with open(osp.join(save_dir, f\"info_{scene_id + 1}.jsonl\"), \"r\") as file:\n",
    "        for line in file:\n",
    "            next_scene_info.append(json.loads(line))\n",
    "    \n",
    "    print(scene_info[-1]['dome']['timestamp'] - offs < next_scene_info[0]['dome']['timestamp'] - offs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c395df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save with labeled boolean\n",
    "for scene_id in range(1, 38):\n",
    "    if scene_id == 18:\n",
    "        print(\"skipping\", scene_id)\n",
    "        continue\n",
    "\n",
    "    scene_info = []\n",
    "    with open(osp.join(save_dir, f\"info_{scene_id}.jsonl\"), \"r\") as file:\n",
    "        for line in file:\n",
    "            timestep_scene_info = json.loads(line)\n",
    "            idx = int(timestep_scene_info['dome']['pcd_filepath'].split(\"/\")[-1].split(\"_\")[1])\n",
    "            is_labeled = idx in labeled_idxs[scene_id]\n",
    "            timestep_scene_info[\"labeled\"] = is_labeled\n",
    "            print(idx, is_labeled)\n",
    "            scene_info.append(timestep_scene_info)\n",
    "    \n",
    "    # Writing JSON lines to a file\n",
    "    save_path = osp.join(save_dir, f\"info_{scene_id}.jsonl\")\n",
    "    with open(save_path, 'w') as file:\n",
    "        for entry in scene_info:\n",
    "            json_line = json.dumps(entry)  # Convert dictionary to JSON string\n",
    "            file.write(json_line + '\\n')  # Write the JSON string to file and move to the next line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09551604",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b594d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
